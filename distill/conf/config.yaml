defaults:
  - _self_

hydra:
  run:
    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}

wandb:
  project: "one-pass-distill"
  entity: null  # Set your wandb entity here if needed
  name: "${now:%Y-%m-%d_%H-%M-%S}"
  mode: "online" # or "disabled" for debugging

data:
  batch_size: 128
  num_workers: 4
  dataset_name: "cifar10" # or "cifar10", etc.
  input_dim: 3*32*32 # for synthetic data
  num_samples: 10000 # for synthetic data

model:
  teacher_hidden_dim: 256
  student_hidden_dim: 128
  output_dim: 10 # Number of classes or output features

distill:
  # PRISM Hyperparameters
  beta: 1.0 # Entropy sensitivity
  eta1: 1.0 # Consensus weight
  eta2: 1.0 # Conflict weight
  lr: 0.01 # Learning rate
  epochs: 15 # Number of epochs
  momentum: 0.9
  weight_decay: 5e-4
  
  # Legacy/Unused
  epsilon: 0.0 # Unused
  alpha: 0.0 # Unused
  projection_dim: 4096 
  activation: "gelu"
  init_scale: 1.0
  init_method: "gaussian"
  scales: [1.0]
  adapter_depth: 2
  solver_device: "cpu"
  use_feature_distillation: true
  low_rank_dim: 0
  num_boosting_stages: 10
